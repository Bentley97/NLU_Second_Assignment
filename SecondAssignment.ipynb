{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondAssignment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/Bentley97/NLU_Second_Assignment/blob/main/SecondAssignment.ipynb",
      "authorship_tag": "ABX9TyMgqCG+DNC1n4X3y+54AX6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bentley97/NLU_Second_Assignment/blob/main/SecondAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULNEUq__Vyf1"
      },
      "source": [
        "# **SECOND ASSIGNMENT**\n",
        "Student:\n",
        "- Name: Luca\n",
        "- Surname: Bentivoglio\n",
        "- Student number: 221246\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB9HUrBUkLor"
      },
      "source": [
        "## **Requirements**\n",
        "To run the notebook are necessary some files that you can find in the 'src' directory.\n",
        "To import it we can simply clone the repository into the notebook and unzip the conll2003 archive, as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rg1qsyNBj4O",
        "outputId": "4c6a25bc-d686-443e-bc41-81ba0d563c21"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/Bentley97/NLU_Second_Assignment.git\n",
        "\n",
        "mkdir NLU_Second_Assignment/src/conll2003\n",
        "\n",
        "unzip -q NLU_Second_Assignment/src/conll2003.zip -d NLU_Second_Assignment/src/conll2003"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLU_Second_Assignment'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9eFw2d6ccA_"
      },
      "source": [
        "##1. Evaluate spaCy NER on CoNLL 2003 data\n",
        "This point is divided in two performance evaluations: the first at token-level, while the second at chunk-level.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D3_DaGcgQHz"
      },
      "source": [
        "To compute performace we take the following steps:\n",
        "- firstly read the test.txt file containing basically the corpus and respective ground truth labels;\n",
        "- load the english pipeline;\n",
        "- cicling over sentences:\n",
        "  - extract words to produce a sentence\n",
        "  - extract the references to compose the list of ground truth to use in evaluation\n",
        "  - pass the sentence to the NER\n",
        "  - post-process the result to reassemble tokens because the parser sometimes splits composed words that need to stay together\n",
        "  - build a list of tuples (text, label) for the sentence, convert its label from spacy format to CoNLL format and append it to the list of hypoteses to evaluate\n",
        "- then convert list of lists of tuples into a list of labels to feed the scikit-learn evaluation function and print results token-level per class (for each combination of IOB-label and tag-label) and in total;\n",
        "- in the end evaluate also performace at chunk-level per class and total.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKl_sbwimRlh"
      },
      "source": [
        "To make the code more readable I split main process in function:\n",
        "\n",
        "`reassemble_tokens(doc)`\n",
        "\n",
        "This is a post-process function that merge tokens splitted by the parser on the basis of the whitespace attribute.\n",
        "\n",
        "Input:\n",
        "- doc ==> spacy Doc element\n",
        "\n",
        "Output:\n",
        "- doc ==> spacy Doc element\n",
        "\n",
        "---\n",
        "`convert_labels_into_conll(doc, convert_dict)`\n",
        "\n",
        "This function simply converts labels according to the mappings of the dict given in input.\n",
        "\n",
        "Input:\n",
        "- doc ==> spacy Doc element \n",
        "- convert_dict ==> dict (of labels)\n",
        "\n",
        "Output:\n",
        "- list of tuples: (text, label) where label is composed by IOB+tag\n",
        "---\n",
        "\n",
        "`convert_in_ordered_list_of_label(l)`\n",
        "\n",
        "This function converts a list of lists of tuples into a list of string(label) with the same order.\n",
        "\n",
        "Input:\n",
        "- l: list of lists of tuples\n",
        "\n",
        "Output:\n",
        "- list of strings\n",
        "\n",
        "---\n",
        "\n",
        "`build_references(sentence)`\n",
        "\n",
        "This function is used to build the list of ground truth returning a list of tuples (text, label) from a sentence given in input in the conll's file format.\n",
        "\n",
        "Input:\n",
        "- sentence: list of strings\n",
        "\n",
        "Output:\n",
        "- list of tuples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XcMlcT_Seqz"
      },
      "source": [
        "### POST-PROCESS reassamble tokens\n",
        "def reassemble_tokens(doc):\n",
        "  i = 0\n",
        "  j = -1\n",
        "  doc_length = len(doc)\n",
        "  while i != doc_length:\n",
        "    if doc[i].whitespace_ == \"\" and doc[i] != doc[-1]:\n",
        "      if j == -1:\n",
        "        j = i\n",
        "    elif j != -1:\n",
        "      with doc.retokenize() as retokenizer:\n",
        "        retokenizer.merge(doc[j:i+1])\n",
        "      doc_length -= i-j\n",
        "      i = j\n",
        "      j = -1\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  return doc\n",
        "\n",
        "### convert labels from the spacy format to the conll format\n",
        "def convert_labels_into_conll(doc, convert_dict):\n",
        "  temp_hyp = []\n",
        "  for token in doc:\n",
        "    if token.ent_type_ == \"\":\n",
        "      temp_hyp.append((token.text, token.ent_iob_))\n",
        "    else:\n",
        "      temp_hyp.append((token.text, token.ent_iob_+\"-\"+convert_dict[token.ent_type_]))\n",
        "    \n",
        "  return temp_hyp\n",
        "\n",
        "### convert a list of lists of tuples into a list of string(label) with the same order\n",
        "def convert_in_ordered_list_of_label(l):\n",
        "  return [tup[1] for sent in l for tup in sent ]\n",
        "  \n",
        "### builds a list of tuples from a text sentence\n",
        "def build_references(sentence):\n",
        "  return [(e0,e3) for elem in sent for e0,e1,e2,e3 in [elem[0].split(\" \")]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wktq4uLvf1C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "c74cc43c-be8e-4511-9ce5-dd3fda0f5a88"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath('NLU_Second_Assignment/src'))\n",
        "\n",
        "from conll import read_corpus_conll\n",
        "from conll import evaluate\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "trn_url = \"NLU_Second_Assignment/src/conll2003/dev.txt\"\n",
        "trn_url = \"NLU_Second_Assignment/src/conll2003/train.txt\"\n",
        "tst_url = \"NLU_Second_Assignment/src/conll2003/test.txt\"\n",
        "\n",
        "convert_dict = {\n",
        "      \"PERSON\": \"PER\",\n",
        "      \"ORG\": \"ORG\",\n",
        "      \"LOC\": \"LOC\",\n",
        "      \"GPE\": \"LOC\",\n",
        "      \"FAC\": \"LOC\",\n",
        "      \"CARDINAL\": \"MISC\",\n",
        "      \"DATE\": \"MISC\",\n",
        "      \"EVENT\": \"MISC\",\n",
        "      \"LANGUAGE\": \"MISC\",\n",
        "      \"LAW\": \"MISC\",\n",
        "      \"MONEY\": \"MISC\",\n",
        "      \"NORP\": \"MISC\",\n",
        "      \"ORDINAL\": \"MISC\",\n",
        "      \"PERCENT\": \"MISC\",\n",
        "      \"PRODUCT\": \"MISC\",\n",
        "      \"QUANTITY\": \"MISC\",\n",
        "      \"TIME\": \"MISC\",\n",
        "      \"WORK_OF_ART\": \"MISC\"\n",
        "  }\n",
        "\n",
        "\n",
        "raw_corpus = read_corpus_conll(tst_url) # reading the file\n",
        "\n",
        "# remove -DOCSTART- lines\n",
        "for r in raw_corpus:\n",
        "  if r[0][0].split(\" \")[0] == \"-DOCSTART-\":\n",
        "    raw_corpus.remove(r)\n",
        "\n",
        "### loading the english pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "hyps = []\n",
        "refs = []\n",
        "\n",
        "### cicle over all sentences in the corpus\n",
        "for sent in raw_corpus:\n",
        "  sentence = \" \".join([elem[0].split(\" \")[0] for elem in sent])\n",
        "  \n",
        "  ### building list of references for a sentence and append it to the list of references of the whole\n",
        "  refs.append(build_references(sentence))\n",
        "  \n",
        "  ### call to the NER of spacy\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  ### POST-PROCESS reassamble tokens\n",
        "  doc = reassemble_tokens(doc)\n",
        "\n",
        "  ### build the list of tuple (text, label) for a sentence converting labels in conll format and appending to list of hypoteses\n",
        "  hyps.append(convert_labels_into_conll(doc, convert_dict))\n",
        "  \n",
        " \n",
        "### adapt hypoteses and references to sklear input format\n",
        "hyps_for_sklearn = convert_in_ordered_list_of_label(hyps)\n",
        "refs_for_sklearn = convert_in_ordered_list_of_label(refs)\n",
        "\n",
        "### extract labels present \n",
        "labels = sorted(list(set(refs_for_sklearn)))\n",
        "\n",
        "\n",
        "### total accuracy is labeld as accuracy\n",
        "print(\"PERFORMANCE token-level:\")\n",
        "print(classification_report(refs_for_sklearn, hyps_for_sklearn, labels=labels, digits=3))\n",
        "\n",
        "print(\"Total accuracy: \",accuracy_score(refs_for_sklearn,hyps_for_sklearn))\n",
        "\n",
        "\n",
        "results = evaluate(refs, hyps)\n",
        "\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"PERFORMANCE chunk-level:\")\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCE token-level:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.786     0.726     0.755      1668\n",
            "      B-MISC      0.091     0.581     0.157       702\n",
            "       B-ORG      0.523     0.337     0.410      1661\n",
            "       B-PER      0.780     0.623     0.693      1617\n",
            "       I-LOC      0.537     0.591     0.563       257\n",
            "      I-MISC      0.055     0.426     0.097       216\n",
            "       I-ORG      0.458     0.550     0.499       835\n",
            "       I-PER      0.736     0.776     0.755      1156\n",
            "           O      0.950     0.839     0.891     38323\n",
            "\n",
            "    accuracy                          0.796     46435\n",
            "   macro avg      0.546     0.606     0.536     46435\n",
            "weighted avg      0.889     0.796     0.835     46435\n",
            "\n",
            "Total accuracy:  0.7956929040594379\n",
            "\n",
            "\n",
            "PERFORMANCE chunk-level:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.464</td>\n",
              "      <td>0.299</td>\n",
              "      <td>0.363</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.151</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.740</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.658</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.777</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.746</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.363</td>\n",
              "      <td>0.539</td>\n",
              "      <td>0.433</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "ORG    0.464  0.299  0.363  1661\n",
              "MISC   0.087  0.558  0.151   702\n",
              "PER    0.740  0.592  0.658  1617\n",
              "LOC    0.777  0.718  0.746  1668\n",
              "total  0.363  0.539  0.433  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkMJOFizkrvD"
      },
      "source": [
        "# **2. Grouping of entities**\n",
        "\n",
        "In this section the objective is to group recognized named entities with the help of `noun_chunk` method of spacy.\n",
        "\n",
        "Then analyze the groups in the CoNLL 2003 file in terms of frequency of the combinations of NER types.\n",
        "\n",
        "To group entities I defined a function:\n",
        "\n",
        "`grouping_entities(doc)`\n",
        "\n",
        "This function cycle over all entities, checks if the entity was already processed, then cycling over all chunks if the chunk isn't empty checks if the entity is contained in a check and groups all the entities of that chunk. Now, if the group created was in a chunk, the function creates a group and append it to a list, otherwise append to the list simply the entity as a single entity group.\n",
        "\n",
        "Input:\n",
        "- doc ==> spacy Doc element\n",
        "\n",
        "Output:\n",
        "- list of lists of strings : where the outer list is the list of groups/chunks and the inner list is the list of entity labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr240bphlmCq"
      },
      "source": [
        "def grouping_entities(doc):\n",
        "  retlist = []\n",
        "  ent_chunked = []\n",
        "  \n",
        "  for ent in doc.ents:\n",
        "    in_chunk = False\n",
        "    if ent[0].idx not in ent_chunked:\n",
        "      for chunk in doc.noun_chunks:\n",
        "        if len(chunk.ents) != 0:\n",
        "          if chunk.ents[0].start_char == ent[0].idx:\n",
        "            in_chunk = True\n",
        "            temp_result = []\n",
        "            for ce in chunk.ents:\n",
        "              temp_result.append(ce.label_)\n",
        "              ent_chunked.append(ce[0].idx)\n",
        "            break\n",
        "      if in_chunk == False:\n",
        "        retlist.append([ent.label_])\n",
        "      else:\n",
        "        retlist.append(temp_result)\n",
        "  \n",
        "  return retlist\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYxuQQVkxfR",
        "outputId": "a76625e8-096f-45ed-b616-754442aae896"
      },
      "source": [
        "import spacy\n",
        "\n",
        "test_sentence = \"Apple's Steve Jobs died in 2011 in Palo Alto , California . Autonomous cars shift insurance liability toward manufacturers in 1996\"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(test_sentence)\n",
        "groups_of_entities = grouping_entities(doc)\n",
        "print(\"Test grouping function\")\n",
        "print(groups_of_entities)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test grouping function\n",
            "[['ORG', 'PERSON'], ['DATE'], ['GPE'], ['GPE'], ['DATE']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZFPbU_--aja"
      },
      "source": [
        "Then, also for counting the number of label combinations in the file I defined a function.\n",
        "\n",
        "As always I cycled over the file sentences extracting groups with the specific function above, I counted the different groups using a dict and printed the results in descending order of frequency.\n",
        "\n",
        "NB: The function takes in consideration the order of the labels in the groups because in my opinion the order of the entities defines also the meaning of the chunk (even if I don't know what type of statistics was refering the request of the assignment).\n",
        "\n",
        "So it considers `['ORG','PERSON']` different from `['PERSON', 'ORG']`.\n",
        "\n",
        "---\n",
        "`counting(groups)`\n",
        "\n",
        "This function defines a dict used to take notes of the counts.\n",
        "\n",
        "Simply, cycling over the list of groups it updates the counts in the dict.\n",
        "\n",
        "Input:\n",
        "- groups ==> list of lists of string : list of groups\n",
        "\n",
        "Output:\n",
        "- dict of counting of groups\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jcK1C1I9wE9"
      },
      "source": [
        "### consider the order\n",
        "def counting(groups):\n",
        "  dict_group = defaultdict(int)\n",
        "\n",
        "  for g in groups:\n",
        "    key = \", \".join([s for s in g])\n",
        "    dict_group[key] = dict_group[key] + 1\n",
        "\n",
        "  return dict_group\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM-Dmgg5NPpX",
        "outputId": "5101334b-dc56-4690-9e68-e9d3c1b94b8c"
      },
      "source": [
        "import spacy \n",
        "from collections import defaultdict\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "groups = []\n",
        "for sent in raw_corpus:\n",
        "  sentence = \" \".join([elem[0].split(\" \")[0] for elem in sent])\n",
        "  \n",
        "  doc = nlp(sentence)\n",
        "  \n",
        "  groups.extend(grouping_entities(doc))\n",
        "\n",
        "counts = counting(groups)\n",
        "sort_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"NE groups frequencies:\")\n",
        "for comb in sort_counts:\n",
        "  print(comb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NE groups frequencies:\n",
            "('CARDINAL', 2116)\n",
            "('GPE', 1346)\n",
            "('DATE', 1140)\n",
            "('PERSON', 1105)\n",
            "('ORG', 955)\n",
            "('NORP', 308)\n",
            "('MONEY', 151)\n",
            "('ORDINAL', 117)\n",
            "('TIME', 92)\n",
            "('PERCENT', 86)\n",
            "('QUANTITY', 82)\n",
            "('EVENT', 58)\n",
            "('LOC', 57)\n",
            "('NORP, PERSON', 47)\n",
            "('CARDINAL, PERSON', 45)\n",
            "('GPE, PERSON', 26)\n",
            "('PRODUCT', 26)\n",
            "('ORG, PERSON', 25)\n",
            "('FAC', 21)\n",
            "('CARDINAL, NORP', 16)\n",
            "('CARDINAL, ORG', 13)\n",
            "('WORK_OF_ART', 12)\n",
            "('GPE, ORG', 11)\n",
            "('GPE, GPE', 11)\n",
            "('CARDINAL, GPE', 11)\n",
            "('PERSON, PERSON', 10)\n",
            "('DATE, EVENT', 9)\n",
            "('ORG, ORG', 9)\n",
            "('LANGUAGE', 8)\n",
            "('LAW', 8)\n",
            "('NORP, ORG', 7)\n",
            "('PERSON, GPE', 6)\n",
            "('DATE, ORG', 6)\n",
            "('GPE, CARDINAL', 5)\n",
            "('DATE, TIME', 5)\n",
            "('DATE, NORP', 5)\n",
            "('ORG, GPE', 4)\n",
            "('CARDINAL, CARDINAL', 4)\n",
            "('NORP, NORP', 4)\n",
            "('GPE, NORP', 4)\n",
            "('ORG, DATE', 4)\n",
            "('CARDINAL, DATE', 3)\n",
            "('ORDINAL, PERSON', 3)\n",
            "('GPE, ORDINAL', 3)\n",
            "('NORP, GPE', 3)\n",
            "('ORDINAL, CARDINAL', 2)\n",
            "('DATE, PRODUCT', 2)\n",
            "('NORP, DATE', 2)\n",
            "('ORG, NORP', 2)\n",
            "('MONEY, ORG', 2)\n",
            "('PERSON, ORG', 2)\n",
            "('ORG, LOC', 2)\n",
            "('DATE, PERSON', 2)\n",
            "('ORDINAL, EVENT', 2)\n",
            "('GPE, FAC', 2)\n",
            "('GPE, DATE', 2)\n",
            "('GPE, LOC', 2)\n",
            "('ORG, PRODUCT', 2)\n",
            "('CARDINAL, LOC', 2)\n",
            "('PERSON, GPE, CARDINAL', 2)\n",
            "('EVENT, CARDINAL', 2)\n",
            "('DATE, CARDINAL', 2)\n",
            "('ORDINAL, NORP', 1)\n",
            "('PERSON, CARDINAL', 1)\n",
            "('ORDINAL, DATE', 1)\n",
            "('PERSON, PERSON, ORG', 1)\n",
            "('ORDINAL, PRODUCT', 1)\n",
            "('CARDINAL, PRODUCT', 1)\n",
            "('PERSON, ORDINAL', 1)\n",
            "('GPE, CARDINAL, GPE', 1)\n",
            "('ORDINAL, ORG', 1)\n",
            "('CARDINAL, PERSON, GPE', 1)\n",
            "('NORP, ORDINAL', 1)\n",
            "('MONEY, EVENT', 1)\n",
            "('CARDINAL, GPE, CARDINAL', 1)\n",
            "('PRODUCT, ORDINAL, NORP', 1)\n",
            "('NORP, PRODUCT', 1)\n",
            "('NORP, NORP, PERSON', 1)\n",
            "('ORG, PERSON, ORG', 1)\n",
            "('LOC, DATE', 1)\n",
            "('NORP, ORDINAL, WORK_OF_ART', 1)\n",
            "('GPE, CARDINAL, NORP', 1)\n",
            "('NORP, ORG, DATE', 1)\n",
            "('LOC, ORDINAL', 1)\n",
            "('MONEY, GPE', 1)\n",
            "('CARDINAL, CARDINAL, ORG', 1)\n",
            "('CARDINAL, PERSON, ORG', 1)\n",
            "('ORDINAL, GPE', 1)\n",
            "('ORG, GPE, LOC, LOC', 1)\n",
            "('MONEY, DATE', 1)\n",
            "('NORP, ORG, QUANTITY', 1)\n",
            "('GPE, ORG, PERSON', 1)\n",
            "('DATE, WORK_OF_ART', 1)\n",
            "('CARDINAL, TIME', 1)\n",
            "('MONEY, MONEY', 1)\n",
            "('PRODUCT, ORG', 1)\n",
            "('ORG, PERCENT, MONEY, CARDINAL, ORG', 1)\n",
            "('PERSON, EVENT', 1)\n",
            "('LOC, NORP', 1)\n",
            "('ORG, WORK_OF_ART', 1)\n",
            "('GPE, ORDINAL, PERSON', 1)\n",
            "('DATE, GPE', 1)\n",
            "('ORG, CARDINAL', 1)\n",
            "('ORG, CARDINAL, ORG', 1)\n",
            "('PRODUCT, PRODUCT', 1)\n",
            "('ORDINAL, ORDINAL', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPKkQvnyCGDc"
      },
      "source": [
        "# **3. Fix segmentation error**\n",
        "\n",
        "The objective of this section is the post-processing step to fix segmentation error. In other words is the practice of extending the entity spans to cover the full noun-compounds. The idea is that the parser sometimes splits nouns that should stay together, so we try to merge them together again to have in theory a better rappresentation.\n",
        "\n",
        "The main part is similar to the first section with the addition of a post-processing elaboration of the hypoteses.\n",
        "\n",
        "In the end, I evaluated the hypoteses obtained in terms of performance at token-level and chunk level, identically to the first section.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This function takes one sentence at each time.\n",
        "Let's see a bit how this function works:\n",
        "\n",
        "- from the sentence already parsed it firstly buils the list of hypotheses (text, labels) that it will update later;\n",
        "- then it extracts the compounds paying attention to not inglobe tokens with `dep_` different from `'compound'`;\n",
        "- finally it updates the hypothesis tuples cycling over entities in the sentence (outer loop), then cycling over compunds(inner loop), it checks if the entity is within a compound... if yes, it extracts the label of the entity nearer to the root of the compound (in case the compound contains more entities with different labels) and updates the hypotheses so that they rappresent the entity span extended to all the compound;\n",
        "- the very final operation of this function is the convertion of the labels from spacy to CoNLL format (to be ready for the evaluation).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "`extend_NE_to_compounds(doc)`\n",
        "\n",
        "Function that extends named entities to its whole noun-compound.\n",
        "\n",
        "Input:\n",
        "- doc ==> spacy Doc element : sentence parsed\n",
        "\n",
        "Output:\n",
        "- list of tuples : list of hypotheses of the sentence converted in CoNLL format\n",
        "\n",
        "---\n",
        "\n",
        "`convert_labels(le)`\n",
        "\n",
        "This is the function that converts the labels from the spacy to CoNLL format\n",
        "\n",
        "Input:\n",
        "- le ==> list of tuples\n",
        "\n",
        "Output:\n",
        "- list of tuples converted\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2f5wQdT6pA6"
      },
      "source": [
        "def extend_NE_to_compounds(doc):\n",
        "\n",
        "  ### build hypoteses to update\n",
        "  h_update = []\n",
        "  for token in doc:\n",
        "    if token.ent_type_ == \"\":\n",
        "      tup = (token.text, token.ent_iob_)\n",
        "    else:\n",
        "      tup = (token.text, token.ent_iob_+\"-\"+token.ent_type_)\n",
        "\n",
        "    h_update.append(tup)\n",
        "\n",
        "\n",
        "  ### extract compounds\n",
        "  compounds = []\n",
        "  head_type = \"\"\n",
        "  comp = []\n",
        "  for token in doc:\n",
        "    if token.dep_ == \"compound\":\n",
        "      headT = token.head\n",
        "      comp.append(token)\n",
        "    else:\n",
        "      if comp:\n",
        "        if token == headT: #to avoid compounds with dep different from 'compound' in the between \n",
        "          comp.append(headT)\n",
        "        \n",
        "        compounds.append(comp)\n",
        "      comp = []\n",
        "      headT = \"\"\n",
        "\n",
        "\n",
        "  ### update hypotheses\n",
        "  for ent in doc.ents:\n",
        "    for c in compounds:\n",
        "      if ent[0].i in [c_elem.i for c_elem in c]:\n",
        "        \n",
        "        tok = c[0]\n",
        "        head_type = \"\"\n",
        "        if tok.ent_type_ != \"\":\n",
        "            head_type = tok.ent_type_\n",
        "        while tok.dep_ == \"compound\":\n",
        "          if tok.head.ent_type_ != \"\":\n",
        "            head_type = tok.head.ent_type_\n",
        "          tok = tok.head\n",
        "\n",
        "\n",
        "        for i in range(c[0].i, (c[-1].i)+1):\n",
        "          if i == c[0].i:\n",
        "            if head_type != \"\":\n",
        "              h_update[i] = (c[i-c[0].i].text, \"B-\"+head_type)\n",
        "            else:\n",
        "              h_update[i] = (c[i-c[0].i].text, \"B-\"+ent.label_)\n",
        "          else:\n",
        "            if head_type != \"\":\n",
        "              h_update[i] = (c[i-c[0].i].text, \"I-\"+head_type)\n",
        "            else:\n",
        "              h_update[i] = (c[i-c[0].i].text, \"I-\"+ent.label_)\n",
        "  \n",
        "\n",
        "  return convert_labels(h_update)\n",
        "\n",
        "\n",
        "def convert_labels(le):\n",
        "  converted = []\n",
        "\n",
        "  for tu in le:\n",
        "    if tu[1] != \"O\":\n",
        "      b = tu[1].split(\"-\")[0] + \"-\" + convert_dict[tu[1].split(\"-\")[1]]\n",
        "      converted.append((tu[0], b))\n",
        "    else:\n",
        "      converted.append(tu)\n",
        "  \n",
        "  return converted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufko-wnQ5lnp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "089b9e1e-40c0-443f-9bbb-1d311cfa98fa"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "hyps_extended = []\n",
        "refs_extended = []\n",
        "\n",
        "for sent in raw_corpus:\n",
        "  sentence = \" \".join([elem[0].split(\" \")[0] for elem in sent])\n",
        "  refs_extended.append(build_references(sentence))\n",
        "\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  # reassemble tokens according to whitespace_\n",
        "  doc = reassemble_tokens(doc)\n",
        "\n",
        "  # extend entity spans to compound spans\n",
        "  hyps_extended.append(extend_NE_to_compounds(doc))\n",
        "\n",
        "\n",
        "\n",
        "### adapt hypoteses and references to sklear input format\n",
        "hyps_for_sklearn_extended = convert_in_ordered_list_of_label(hyps_extended)\n",
        "refs_for_sklearn_extended = convert_in_ordered_list_of_label(refs_extended)\n",
        "\n",
        "### extract labels present \n",
        "labels = sorted(list(set(refs_for_sklearn_extended)))\n",
        "\n",
        "\n",
        "### total accuracy is labeld as accuracy\n",
        "print(\"PERFORMANCE token-level:\")\n",
        "print(classification_report(refs_for_sklearn_extended, hyps_for_sklearn_extended, labels=labels, digits=3))\n",
        "\n",
        "print(\"Total accuracy: \",accuracy_score(refs_for_sklearn_extended,hyps_for_sklearn_extended))\n",
        "\n",
        "\n",
        "results = evaluate(refs, hyps_extended)\n",
        "\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"PERFORMANCE chunk-level:\")\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCE token-level:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.769     0.700     0.733      1668\n",
            "      B-MISC      0.090     0.566     0.155       702\n",
            "       B-ORG      0.505     0.316     0.389      1661\n",
            "       B-PER      0.640     0.505     0.565      1617\n",
            "       I-LOC      0.311     0.599     0.410       257\n",
            "      I-MISC      0.050     0.454     0.090       216\n",
            "       I-ORG      0.367     0.547     0.440       835\n",
            "       I-PER      0.560     0.780     0.652      1156\n",
            "           O      0.952     0.817     0.879     38323\n",
            "\n",
            "    accuracy                          0.771     46435\n",
            "   macro avg      0.472     0.587     0.479     46435\n",
            "weighted avg      0.878     0.771     0.815     46435\n",
            "\n",
            "Total accuracy:  0.7712070636373425\n",
            "\n",
            "\n",
            "PERFORMANCE chunk-level:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.358</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.276</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.075</td>\n",
              "      <td>0.476</td>\n",
              "      <td>0.130</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.588</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.520</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.711</td>\n",
              "      <td>0.647</td>\n",
              "      <td>0.677</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.307</td>\n",
              "      <td>0.449</td>\n",
              "      <td>0.365</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "ORG    0.358  0.224  0.276  1661\n",
              "MISC   0.075  0.476  0.130   702\n",
              "PER    0.588  0.465  0.520  1617\n",
              "LOC    0.711  0.647  0.677  1668\n",
              "total  0.307  0.449  0.365  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMBgFR22OhZx"
      },
      "source": [
        "It seems that I obtained worse results, maybe because I missed something in the post-processing elaboration or probably because this method used on this specific text file produces some entity expansions not very correct (where they aren't necessary)"
      ]
    }
  ]
}