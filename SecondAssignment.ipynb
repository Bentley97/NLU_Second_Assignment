{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondAssignment.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Bentley97/NLU_Second_Assignment/blob/main/SecondAssignment.ipynb",
      "authorship_tag": "ABX9TyNR7hyTlGFgPfz0ZiZfE9hZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bentley97/NLU_Second_Assignment/blob/main/SecondAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB9HUrBUkLor"
      },
      "source": [
        "To clone the repository into the notebook and unzip the conll2003 archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rg1qsyNBj4O",
        "outputId": "7220214f-8957-403e-ab5a-444738a793fd"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/Bentley97/NLU_Second_Assignment.git\n",
        "\n",
        "mkdir NLU_Second_Assignment/src/conll2003\n",
        "\n",
        "unzip -q NLU_Second_Assignment/src/conll2003.zip -d NLU_Second_Assignment/src/conll2003"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLU_Second_Assignment'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XcMlcT_Seqz"
      },
      "source": [
        "### POST-PROCESS reassamble tokens\n",
        "def reassemble_tokens(doc):\n",
        "  i = 0\n",
        "  j = -1\n",
        "  doc_length = len(doc)\n",
        "  while i != doc_length:\n",
        "    if doc[i].whitespace_ == \"\" and doc[i] != doc[-1]:\n",
        "      if j == -1:\n",
        "        j = i\n",
        "    elif j != -1:\n",
        "      with doc.retokenize() as retokenizer:\n",
        "        retokenizer.merge(doc[j:i+1])\n",
        "      doc_length -= i-j\n",
        "      i = j\n",
        "      j = -1\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  return doc\n",
        "\n",
        "### convert labels from the spacy format to the conll format\n",
        "def convert_labels_into_conll(doc):\n",
        "  temp_hyp = []\n",
        "  for token in doc:\n",
        "    if token.ent_type_ == \"\":\n",
        "      temp_hyp.append((token.text, token.ent_iob_))\n",
        "    else:\n",
        "      if token.ent_type_ == \"PERSON\":\n",
        "        temp_hyp.append((token.text, token.ent_iob_+\"-PER\"))\n",
        "      elif token.ent_type_ == \"ORG\":\n",
        "        temp_hyp.append((token.text, token.ent_iob_+\"-ORG\"))\n",
        "      elif token.ent_type_ == \"LOC\" or token.ent_type_ == \"GPE\" or token.ent_type_ == \"FAC\":\n",
        "        temp_hyp.append((token.text, token.ent_iob_+\"-LOC\"))\n",
        "      else:\n",
        "        temp_hyp.append((token.text, token.ent_iob_+\"-MISC\")) #includes also numbers (CARDINAL,DATE,MONEY,ORDINAL,PERCENT,QUANTITY,TIME)\n",
        "\n",
        "  return temp_hyp\n",
        "\n",
        "### convert a list of lists of tuples into a list of string(label) with the same order\n",
        "def convert_in_ordered_list_of_label(l):\n",
        "  return [tup[1] for sent in l for tup in sent ]\n",
        "  \n",
        "### builds a list of tuples from a text sentence\n",
        "def build_references(sentence):\n",
        "  return [(e0,e3) for elem in sent for e0,e1,e2,e3 in [elem[0].split(\" \")]]\n",
        "\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wktq4uLvf1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b8f2ef-20d8-4de4-a95d-6b24a6ad52bc"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath('NLU_Second_Assignment/src'))\n",
        "\n",
        "from conll import read_corpus_conll\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "trn_url = \"NLU_Second_Assignment/src/conll2003/dev.txt\"\n",
        "trn_url = \"NLU_Second_Assignment/src/conll2003/train.txt\"\n",
        "tst_url = \"NLU_Second_Assignment/src/conll2003/test.txt\"\n",
        "\n",
        "\n",
        "raw_corpus = read_corpus_conll(tst_url) # reading the file\n",
        "raw_corpus.remove(raw_corpus[0])  # remove -DOCSTAR-\n",
        "\n",
        "### loading the english pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "hyps = []\n",
        "refs = []\n",
        "\n",
        "### cicle over all sentences in the corpus\n",
        "for sent in raw_corpus:\n",
        "  sentence = \" \".join([elem[0].split(\" \")[0] for elem in sent])\n",
        "  \n",
        "  ### building list of references for a sentence and append it to the list of references of the whole\n",
        "  refs.append(build_references(sentence))\n",
        "  \n",
        "  ### call to the NER of spacy\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  ### POST-PROCESS reassamble tokens\n",
        "  doc = reassemble_tokens(doc)\n",
        "\n",
        "  ### build the list of tuple (text, label) for a sentence converting labels in conll format and appending to list of hypoteses\n",
        "  hyps.append(convert_labels_into_conll(doc))\n",
        "  \n",
        " \n",
        "### adapt hypoteses and references to sklear input format\n",
        "hyps_for_sklearn = convert_in_ordered_list_of_label(hyps)\n",
        "refs_for_sklearn = convert_in_ordered_list_of_label(refs)\n",
        "\n",
        "### extract labels present \n",
        "labels = sorted(list(set(refs_for_sklearn)))\n",
        "\n",
        "\n",
        "### total accuracy is labeld as accuracy\n",
        "print(\"PERFORMANCES token-level:\")\n",
        "print(classification_report(refs_for_sklearn, hyps_for_sklearn, labels=labels, digits=3))\n",
        "\n",
        "print(\"Total accuracy: \",accuracy_score(refs_for_sklearn,hyps_for_sklearn))\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCES token-level:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC      0.786     0.726     0.755      1668\n",
            "      B-MISC      0.091     0.581     0.157       702\n",
            "       B-ORG      0.523     0.337     0.410      1661\n",
            "       B-PER      0.780     0.623     0.693      1617\n",
            "       I-LOC      0.537     0.591     0.563       257\n",
            "      I-MISC      0.055     0.426     0.097       216\n",
            "       I-ORG      0.458     0.550     0.499       835\n",
            "       I-PER      0.736     0.776     0.755      1156\n",
            "           O      0.950     0.840     0.892     38553\n",
            "\n",
            "    accuracy                          0.797     46665\n",
            "   macro avg      0.546     0.606     0.536     46665\n",
            "weighted avg      0.890     0.797     0.836     46665\n",
            "\n",
            "Total accuracy:  0.7966998821386478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqy3VmDnH3Wi"
      },
      "source": [
        "**EVALUATE FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "FyQKvkDTCOFw",
        "outputId": "06fc3dda-31ce-47ec-a62f-a2274e6566da"
      },
      "source": [
        "from conll import evaluate\n",
        "import pandas as pd\n",
        "\n",
        "results = evaluate(refs, hyps)\n",
        "\n",
        "print(\"PERFORMANCES chunk-level:\")\n",
        "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCES chunk-level:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.777</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.746</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.087</td>\n",
              "      <td>0.558</td>\n",
              "      <td>0.151</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.464</td>\n",
              "      <td>0.299</td>\n",
              "      <td>0.363</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.740</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.658</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.363</td>\n",
              "      <td>0.539</td>\n",
              "      <td>0.433</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "LOC    0.777  0.718  0.746  1668\n",
              "MISC   0.087  0.558  0.151   702\n",
              "ORG    0.464  0.299  0.363  1661\n",
              "PER    0.740  0.592  0.658  1617\n",
              "total  0.363  0.539  0.433  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kYWd3LnNwsI"
      },
      "source": [
        "####################################################     NON SERVE     ######################################################\n",
        "def extract_label(refs, hyps, label):\n",
        "  r = []\n",
        "  h = []\n",
        "\n",
        "  for i in range(len(refs)):\n",
        "    if hyps[i] == label:\n",
        "    #if refs[i] == label or hyps[i] == label or refs[i] != hyps[i]:\n",
        "      r.append(refs[i])\n",
        "      h.append(hyps[i])\n",
        "  \n",
        "  return r,h"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}